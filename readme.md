| |[EasyTeaching: A Keyframe-Driven Framework for Robotic Manipulation Learning](https://github.com/Yanxxx/EasyTeaching/blob/main/README.md) |
| ------------- |  ------------- |
| AAA | The EasyTeaching framework is designed to empower robots to learn complex manipulation tasks using a <ins>**limited number of human-operated demonstrations**</ins>. Developed in 2021, the approach aims to simplify robot teaching for **NON-EXPERTS** while overcoming common challenges such as **noisy data, exploration inefficiencies, and the scarcity of demonstration episodes**. | 
| | Teleoperated Colabration Robot Digital Twin |
| |  Wearable ego-motion tracking for blind navigation in indoor environments |
| | Relative motion estimation using visual–inertial optical flow |
| | Spatial calibration for thermal-rgb cameras and inertial sensor system |
| | Rotational coordinate transformation for visual-inertial sensor fusion |
| | |
| | |

The EasyTeaching framework is designed to empower robots to learn complex manipulation tasks using a <ins>**limited number of human-operated demonstrations**</ins>. Developed in 2021, the approach aims to simplify robot teaching for **NON-EXPERTS** while overcoming common challenges such as **noisy data, exploration inefficiencies, and the scarcity of demonstration episodes**.

### 

### Wearable ego-motion tracking for blind navigation in indoor environments

### Relative motion estimation using visual–inertial optical flow

### Spatial calibration for thermal-rgb cameras and inertial sensor system

### Rotational coordinate transformation for visual-inertial sensor fusion

### 
